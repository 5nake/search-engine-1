http://www.cs.dartmouth.edu/~erickee/publications.html#pnas11
3
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><style type="text/css">
<!--
body {
	background-color: #868686;
	background-image: url(blackbg.gif);
}
body,td,th {
	color: #E1D0B4;
}
a:link {
	color: #E5B26A;
}
a:visited {
	color: #E5B26A;
}
a:hover {
	color: #FFC674;
}
a:active {
	color: #EAE0D2;
}
.style4 {
	color: #E1D0B4;
	font-weight: bold;
}
-->
</style>
<body>
<table width="90%" border="0" align="center" cellpadding="3">
  <tr>
    <td colspan="2"><h2><dfn>p u b l i c a t i o n s <hr> </dfn></h2></td>
  </tr>
  <tr>
    <td rowspan="2"><img src="papers/covers/moonlanding_analysis.jpg" width="200" height="214" alt="Shadows"></a></td>
    <td><a name=tog13 id="tog13"></a><strong>Exposing Photo Manipulation with Inconsistent Shadows</strong><br>
&nbsp;&nbsp;&nbsp;&nbsp;E. Kee, J. O'Brien, H. Farid<br>
&nbsp;&nbsp;&nbsp;&nbsp;Transactions on Graphics / SIGGRAPH, 2013<br>
    <a href="papers/tog13.pdf">Paper</a>&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="papers/tog13.bib">Bibtex</a>&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="papers/tog13/interface.mov">User interface demo</a>&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="papers/tog13/subject.mov">Test subject analyzing a photo</a>&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="papers/tog13/perceptual.pdf">Examples from perceptual study</a>&nbsp;&nbsp;&nbsp;&nbsp;
  </tr>
  <tr>
    <td valign="top">
We describe a geometric technique to detect physically inconsistent arrangements of shadows in an image. This technique combines multiple constraints from cast and attached shadows to constrain the projected location of a point light source. The consistency of the shadows is posed as a linear programming problem. A feasible solution indicates that the collection of shadows is physically plausible, while a failure to find a solution provides evidence of photo tampering.</td>
  </tr>
  <tr>
    <td colspan="2">&nbsp;</td>
  </tr>

  <tr>
    <td rowspan="2"><a href="howmodified/figures/metric_small.jpg"> <img src="papers/covers/retouching.jpg" width="200" height="214" alt="Retouching"></a></td>
    <td><a name=pnas11 id="pnas11"></a><strong>A Perceptual Metric for Photo Retouching</strong><br>
&nbsp;&nbsp;&nbsp;&nbsp;E. Kee, H. Farid<br>
&nbsp;&nbsp;&nbsp;&nbsp;Proceedings of the National Academy of Sciences, 2011<br>
    <a href="http://www.pnas.org/content/early/2011/11/21/1110747108.abstract">Paper</a>&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="papers/pnas11.bib">Bibtex</a>&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="http://www.cs.dartmouth.edu/farid/Hany_Farid/photoretouching.html">Supplemental Material</a>&nbsp;&nbsp;&nbsp;&nbsp;
    <!-- <a href="http://www.cs.dartmouth.edu/farid/downloads/publications/pnas11/">Interactive Figures</a>&nbsp;&nbsp;&nbsp;&nbsp -->
    <a href="http://www.pnas.org/content/early/2011/11/21/1110747108/suppl/DCSupplemental">PNAS Supporting Information</a>&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="press/pnas11.html">Press</a></td>
  </tr>
  <tr>
    <td valign="top">In recent years, advertisers and magazine editors have been widely criticized for taking digital photo retouching to an extreme. Impossibly thin, tall, and wrinkle- and blemish-free models are routinely splashed onto billboards, advertisements, and magazine covers. The ubiquity of these unrealistic and highly idealized images has been linked to eating disorders and body image dissatisfaction in men, women, and children. In response, several countries have considered legislating the labeling of retouched photos. We describe a quantitative and perceptually meaningful metric of photo retouching. Photographs are rated on the degree to which they have been digitally altered by explicitly modeling and estimating geometric and photometric changes. This metric correlates well with perceptual judgments of photo retouching and can be used to objectively judge by how much a retouched photo has strayed from reality.</td>
  </tr>
  <tr>
    <td colspan="2">&nbsp;</td>
  </tr>

  <tr>
    <td rowspan="2"><img src="papers/covers/jpegheaders.jpg" width="200" height="214" alt="Headers"></td>
    <td><a name=tifs11></a><strong>Digital Image Authentication from JPEG Headers</strong><br>
&nbsp;&nbsp;&nbsp;&nbsp;E. Kee, M. K. Johnson, H. Farid<br>
&nbsp;&nbsp;&nbsp;&nbsp;IEEE Transactions on Information Forensics and Security, 2011<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="papers/tifs11.pdf">Paper</a>&nbsp;&nbsp;&nbsp;&nbsp;<a href="papers/tifs11.bib">Bibtex</a></td>
  </tr>
  <tr>
    <td valign="top">It is often desirable to determine if an image has been modified in any way from its original recording. The JPEG format affords engineers many implementation trade-offs which give rise to widely varying JPEG headers. We exploit these variations for image authentication. A camera signature is extracted from a JPEG image consisting of information about quantization tables, Huffman codes, thumbnails, and EXIF format. We show that this signature is highly distinct across 1.3 million images spanning 773 different cameras and cellphones. Specifically, 62% of images have a signature that is unique to a single camera, 80% of images have a signature that is shared by three or fewer cameras, and 99% of images have a signature that is unique to a single manufacturer. The signature of Adobe Photoshop is also shown to be unique relative to all 773 cameras. These signatures are simple to extract and offer an efficient method to establish the authenticity of a digital image.</td>
  </tr>
  <tr>
    <td colspan="2">&nbsp;</td>
  </tr>

  <tr>
    <td rowspan="2"><img src="papers/covers/deblur.jpg" width="200" height="214" alt="Deblurring"></td>
    <td><a name=iccp11></a><strong>Modeling and Removing Spatially-Varying Optical Blur</strong><br>
&nbsp;&nbsp;&nbsp;&nbsp;E. Kee, S. Paris, S. Chen, J. Wang<br>
&nbsp;&nbsp;&nbsp;    IEEE International Conference on Computational Photography, 2011 <br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="papers/iccp11.pdf">Paper</a>&nbsp;&nbsp;&nbsp;&nbsp;<a href="papers/iccp11.bib">Bibtex</a>&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://www.juew.org/lensblur/materials.zip">Supplemental Material </a>&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://www.youtube.com/watch?v=dG3kuoN1JOc">Presentation</a></td>
  </tr>
  <tr>
    <td valign="top">Photo deblurring has been a major research topic in the past few years. So far, existing methods have focused on removing the blur due to camera shake and object motion. In this paper, we show that the optical system of the camera also generates significant blur, even with professional lenses. We introduce a method to estimate the blur kernel densely over the image and across multiple aperture and zoom settings. Our measures show that the blur kernel can have a non-negligible spread, even with top-of-the-line equipment, and that it varies nontrivially over this domain. In particular, the spatial variations are not radially symmetric and not even left-right symmetric. We develop and compare two models of the optical blur, each of them having its own advantages. We show that our models predict accurate blur kernels that can be used to restore photos. We demonstrate that we can produce images that are more uniformly sharp unlike those produced with spatially-invariant deblurring techniques.</td>
  </tr>
  <tr>
    <td colspan="2">&nbsp;</td>
  </tr>
  <tr>
    <td rowspan="2"><img src="papers/covers/facelighting1.jpg" width="200" height="214" alt="Complex"></td>
    <td><a name=wifs10></a><strong>Exposing Digital Forgeries from 3-D Lighting Environments</strong><br>
&nbsp;&nbsp;&nbsp;&nbsp;E. Kee, H. Farid<br>
&nbsp;&nbsp;&nbsp;    IEEE International Workshop on Information Forensics and Security, 2010<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="papers/wifs10.pdf">Paper</a>&nbsp;&nbsp;&nbsp;&nbsp;<a href="papers/wifs10.bib">Bibtex</a></td>
  </tr>
  <tr>
    <td valign="top">When creating a photographic composite, it can be difficult to match lighting conditions. We describe a technique for measuring lighting conditions in an image, and describe its use in detecting photographic composites. Specifically, we describe how to approximate a 3-D lighting environment with a low-dimensional model and how to estimate the model's parameters from a single image. Inconsistencies in the lighting model are then used as evidence of tampering.</td>
  </tr>
  
  <tr>
    <td colspan="2">&nbsp;</td>
  </tr>
  <tr>
    <td rowspan="2"><img src="papers/covers/thumbnails.jpg" width="200" height="213" alt="Thumbnails"></td>
    <td><a name=spie10></a><strong>Digital Image Authentication from Thumbnails</strong><br>
&nbsp;&nbsp;&nbsp;&nbsp;E. Kee, H. Farid<br>
&nbsp;&nbsp;&nbsp;    SPIE Symposium on Electronic Imaging, San Jose, CA, 2010<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="papers/spie10.pdf">Paper</a>&nbsp;&nbsp;&nbsp;&nbsp;<a href="papers/spie10.bib">Bibtex</a></td>
  </tr>
  <tr>
    <td valign="top">
    We describe how to exploit the formation and storage of an embedded image thumbnail for image authentication. The creation of a thumbnail is modeled with a series of filtering operations, contrast adjustment, and compression. We automatically estimate these model parameters and show that these parameters differ significantly between camera manufacturers and photo-editing software. We also describe how this signature can be combined with encoding information from the underlying full resolution image to further refine the signature's distinctiveness. </td>
  </tr>
  <tr>
    <td colspan="2">&nbsp;</td>
  </tr>
  <tr>
    <td rowspan="2"><img src="papers/covers/famous.jpg" width="200" height="144"></td>
    <td><a name=tr09></a><strong>Detecting Photographic Composites of Famous People</strong><br>
&nbsp;&nbsp;&nbsp;&nbsp;E. Kee, H. Farid<br>
&nbsp;&nbsp;&nbsp;    Technical Report, TR2009-656, Dartmouth College, Computer Science<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="papers/tr09.pdf">Paper</a>&nbsp;&nbsp;&nbsp;&nbsp;<a href="papers/tr09.bib">Bibtex</a></td>
  </tr>
  <tr>
    <td>Photos are commonly falsified by compositing two or more people into a single image. We describe how such composites can be detected by estimating a camera's intrinsic parameters. Differences in these parameters across the image are then used as evidence of tampering. Expanding on earlier work, this approach is more applicable to low-resolution images, but requires a reference image of each person in the photo as they are directly facing the camera. When considering composites of famous people, such a reference photo is easily obtained from an on-line image search.</td>
  </tr>
  <tr>
    <td colspan="2">&nbsp;</td>
  </tr>
  <tr>
    <td rowspan="2"><img src="papers/covers/msl.jpg" width="200" height="185" alt="msl"></td>
    <td><a name=neuro10></a><span class="style4">A novel approach for semi-automated segmentation of MS lesions on FLAIR imaging: Reliability and clinical correlates</span><br>
&nbsp;&nbsp;&nbsp; Wishart, H., Kee, E.R., Ford, J.C., MacDonald, J.W.,  Aney, S., LoVerde, S. <br>
&nbsp;&nbsp;&nbsp;    Annual Meeting of the International Neuropsychological Society, Acapulco, Mexico, February 3-6, 2010</td>
  </tr>
  <tr>
    <td valign="top">Rapid, reliable methods for segmenting and quantifying MS lesions on brain magnetic resonance imaging are important for monitoring patients over time. This work describes  a novel approach for semi-automated segmentation of MS lesions on fluid-attenuated inversion recovery (FLAIR) images. </td>
  </tr>
  
  <tr>
    <td colspan="2">&nbsp;</td>
  </tr>
  <tr>
    <td width="13" rowspan="2"><img src="papers/covers/printer.jpg" width="200" height="214" alt="Printers"></td>
    <td><a name=acm08></a><strong>Printer Profiling for Forensics and Ballistics</strong><br>
&nbsp;&nbsp;&nbsp;&nbsp;E. Kee, H. Farid<br>
&nbsp;&nbsp;&nbsp;    ACM Multimedia and Security Workshop, Oxford, UK, 2008 <br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="papers/acm08.pdf">Paper</a>&nbsp;&nbsp;&nbsp;&nbsp;<a href="papers/acm08.bib">Bibtex</a></td>
  </tr>
  <tr>
    <td width="941" valign="top">We describe a technique for authenticating printed and scanned text documents. This technique works by modeling the degradation in a document caused by printing. The resulting printer profile is then used to detect inconsistencies across a document, and for ballistic purposes -- that of linking a document to a printer. </td>
  </tr>
</table>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
</body>
</html>
